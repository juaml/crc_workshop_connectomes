{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0853fa4e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Title of the thing\n",
    "\n",
    "This is where I would put additional explanations if I knew what I want to say. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdac596",
   "metadata": {},
   "source": [
    "## The AOMIC Data\n",
    "\n",
    "First, lets load the data and inspect it a bit. The [AOMIC dataset](https://nilab-uva.github.io/AOMIC.github.io/) is a collection data obtained in three different studies (**PIOP1**, **PIOP2**, **ID1000**). Here, we will be only concerned with the data from the **ID1000** study, which aimed to collect 1000 fMRI scans during movie-watching. The next cell defines the path to all the **ID1000** specific data, and also adds the names of the two files we will be interested in. One of these files contains the preprocessed **functional connectivity (FC)** data, whereas the other file contains the important **demographic** information. Let's start by also loading the dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbd1570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e368676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to ID1000 data within the AOMIC datalad dataset\n",
    "ID1000_path = (\n",
    "    Path(\"..\") / \"aomic-fc\"/ \"junifer_storage\" / \n",
    "    \"JUNIFER_AOMIC_TSV_CONNECTOMES\" / \"ID1000\"\n",
    ")\n",
    "\n",
    "# Path to the demographics data file\n",
    "demographics_path = ID1000_path / \"ID1000_participants.tsv\"\n",
    "\n",
    "# Path to the connectomes data file\n",
    "# The name of this file is a bit of a mouthful but contains important\n",
    "# information\n",
    "connectomes_path = ID1000_path / (\n",
    "    \"ID1000_BOLD_parccortical-Schaefer100x17FSLMNI_\"\n",
    "    \"parcsubcortical-TianxS2x3TxMNInonlinear2009cAsym_\"\n",
    "    \"marker-empiricalFC_moviewatching.tsv.gz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dd60e7",
   "metadata": {},
   "source": [
    "### Demographic Data\n",
    "\n",
    "Now that we have defined these paths let's load each file and look at them one by one. Let's start with the demographics. We will load it using pandas, and as you might see from the file extension, these are both **tsv** files and we will therefore load them using a tab as a delimiter. In addition, we will load the first column as the index of the dataframe as it happens to contain the subject ID's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f086b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>handedness</th>\n",
       "      <th>BMI</th>\n",
       "      <th>education_level</th>\n",
       "      <th>background_SES</th>\n",
       "      <th>IST_fluid</th>\n",
       "      <th>IST_memory</th>\n",
       "      <th>IST_crystallised</th>\n",
       "      <th>IST_intelligence_total</th>\n",
       "      <th>...</th>\n",
       "      <th>sexual_attraction_M</th>\n",
       "      <th>sexual_attraction_F</th>\n",
       "      <th>gender_identity_M</th>\n",
       "      <th>gender_identity_F</th>\n",
       "      <th>religious_upbringing</th>\n",
       "      <th>religious_now</th>\n",
       "      <th>religious_importance</th>\n",
       "      <th>DWI_TR_run1</th>\n",
       "      <th>DWI_TR_run2</th>\n",
       "      <th>DWI_TR_run3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub-0001</th>\n",
       "      <td>22.00</td>\n",
       "      <td>female</td>\n",
       "      <td>right</td>\n",
       "      <td>23</td>\n",
       "      <td>medium</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.312</td>\n",
       "      <td>6.312</td>\n",
       "      <td>6.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0002</th>\n",
       "      <td>21.75</td>\n",
       "      <td>female</td>\n",
       "      <td>right</td>\n",
       "      <td>20</td>\n",
       "      <td>medium</td>\n",
       "      <td>5.5</td>\n",
       "      <td>97.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0003</th>\n",
       "      <td>25.25</td>\n",
       "      <td>female</td>\n",
       "      <td>right</td>\n",
       "      <td>31</td>\n",
       "      <td>high</td>\n",
       "      <td>3.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.312</td>\n",
       "      <td>6.312</td>\n",
       "      <td>6.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0004</th>\n",
       "      <td>22.50</td>\n",
       "      <td>female</td>\n",
       "      <td>right</td>\n",
       "      <td>20</td>\n",
       "      <td>high</td>\n",
       "      <td>5.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0005</th>\n",
       "      <td>22.25</td>\n",
       "      <td>male</td>\n",
       "      <td>right</td>\n",
       "      <td>23</td>\n",
       "      <td>high</td>\n",
       "      <td>4.5</td>\n",
       "      <td>112.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0924</th>\n",
       "      <td>22.25</td>\n",
       "      <td>male</td>\n",
       "      <td>right</td>\n",
       "      <td>21</td>\n",
       "      <td>medium</td>\n",
       "      <td>3.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.374</td>\n",
       "      <td>6.374</td>\n",
       "      <td>6.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0925</th>\n",
       "      <td>25.25</td>\n",
       "      <td>male</td>\n",
       "      <td>right</td>\n",
       "      <td>30</td>\n",
       "      <td>medium</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0926</th>\n",
       "      <td>20.75</td>\n",
       "      <td>male</td>\n",
       "      <td>right</td>\n",
       "      <td>22</td>\n",
       "      <td>high</td>\n",
       "      <td>2.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.312</td>\n",
       "      <td>6.312</td>\n",
       "      <td>6.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0927</th>\n",
       "      <td>24.25</td>\n",
       "      <td>female</td>\n",
       "      <td>right</td>\n",
       "      <td>35</td>\n",
       "      <td>medium</td>\n",
       "      <td>2.5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0928</th>\n",
       "      <td>20.50</td>\n",
       "      <td>male</td>\n",
       "      <td>left</td>\n",
       "      <td>19</td>\n",
       "      <td>high</td>\n",
       "      <td>5.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.374</td>\n",
       "      <td>6.374</td>\n",
       "      <td>6.374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>928 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  age     sex handedness  BMI education_level  background_SES  \\\n",
       "participant_id                                                                  \n",
       "sub-0001        22.00  female      right   23          medium             2.0   \n",
       "sub-0002        21.75  female      right   20          medium             5.5   \n",
       "sub-0003        25.25  female      right   31            high             3.0   \n",
       "sub-0004        22.50  female      right   20            high             5.0   \n",
       "sub-0005        22.25    male      right   23            high             4.5   \n",
       "...               ...     ...        ...  ...             ...             ...   \n",
       "sub-0924        22.25    male      right   21          medium             3.0   \n",
       "sub-0925        25.25    male      right   30          medium             4.0   \n",
       "sub-0926        20.75    male      right   22            high             2.0   \n",
       "sub-0927        24.25  female      right   35          medium             2.5   \n",
       "sub-0928        20.50    male       left   19            high             5.0   \n",
       "\n",
       "                IST_fluid  IST_memory  IST_crystallised  \\\n",
       "participant_id                                            \n",
       "sub-0001             77.0        49.0              33.0   \n",
       "sub-0002             97.0        63.0              39.0   \n",
       "sub-0003            122.0        67.0              38.0   \n",
       "sub-0004            149.0        69.0              52.0   \n",
       "sub-0005            112.0        57.0              43.0   \n",
       "...                   ...         ...               ...   \n",
       "sub-0924            136.0        56.0              54.0   \n",
       "sub-0925             64.0        37.0              49.0   \n",
       "sub-0926             84.0        44.0              33.0   \n",
       "sub-0927             98.0        57.0              35.0   \n",
       "sub-0928            135.0        59.0              49.0   \n",
       "\n",
       "                IST_intelligence_total  ...  sexual_attraction_M  \\\n",
       "participant_id                          ...                        \n",
       "sub-0001                         159.0  ...                  7.0   \n",
       "sub-0002                         199.0  ...                  7.0   \n",
       "sub-0003                         227.0  ...                  6.0   \n",
       "sub-0004                         270.0  ...                  6.0   \n",
       "sub-0005                         212.0  ...                  1.0   \n",
       "...                                ...  ...                  ...   \n",
       "sub-0924                         246.0  ...                  2.0   \n",
       "sub-0925                         150.0  ...                  1.0   \n",
       "sub-0926                         161.0  ...                  NaN   \n",
       "sub-0927                         190.0  ...                  7.0   \n",
       "sub-0928                         243.0  ...                  NaN   \n",
       "\n",
       "                sexual_attraction_F  gender_identity_M  gender_identity_F  \\\n",
       "participant_id                                                              \n",
       "sub-0001                        1.0                1.0                7.0   \n",
       "sub-0002                        1.0                2.0                7.0   \n",
       "sub-0003                        3.0                1.0                6.0   \n",
       "sub-0004                        2.0                1.0                7.0   \n",
       "sub-0005                        7.0                6.0                1.0   \n",
       "...                             ...                ...                ...   \n",
       "sub-0924                        6.0                4.0                4.0   \n",
       "sub-0925                        7.0                7.0                1.0   \n",
       "sub-0926                        NaN                NaN                NaN   \n",
       "sub-0927                        2.0                1.0                7.0   \n",
       "sub-0928                        NaN                NaN                NaN   \n",
       "\n",
       "                religious_upbringing  religious_now  religious_importance  \\\n",
       "participant_id                                                              \n",
       "sub-0001                          no            yes                   2.0   \n",
       "sub-0002                          no             no                   NaN   \n",
       "sub-0003                          no             no                   NaN   \n",
       "sub-0004                         yes             no                   NaN   \n",
       "sub-0005                          no             no                   NaN   \n",
       "...                              ...            ...                   ...   \n",
       "sub-0924                          no             no                   NaN   \n",
       "sub-0925                          no             no                   NaN   \n",
       "sub-0926                         yes            yes                   5.0   \n",
       "sub-0927                          no             no                   NaN   \n",
       "sub-0928                          no             no                   NaN   \n",
       "\n",
       "                DWI_TR_run1  DWI_TR_run2  DWI_TR_run3  \n",
       "participant_id                                         \n",
       "sub-0001              6.312        6.312        6.312  \n",
       "sub-0002                NaN        6.311        6.311  \n",
       "sub-0003              6.312        6.312        6.312  \n",
       "sub-0004              6.311        6.311        6.311  \n",
       "sub-0005              6.311        6.311        6.311  \n",
       "...                     ...          ...          ...  \n",
       "sub-0924              6.374        6.374        6.374  \n",
       "sub-0925              6.311        6.311        6.311  \n",
       "sub-0926              6.312        6.312        6.312  \n",
       "sub-0927              6.311        6.311        6.311  \n",
       "sub-0928              6.374        6.374        6.374  \n",
       "\n",
       "[928 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics = pd.read_csv(demographics_path, sep=\"\\t\", index_col=0)\n",
    "demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd6b297",
   "metadata": {},
   "source": [
    "We can see some of the standard demographic variables, like \"age\", \"sex\", \"BMI\", and so on. As you might be able to tell, however, this file not *only* contains \"demographic\" information but also some other participant data, as for example cognitive measurements (e.g. \"IST_memory\", \"IST_fluid\").\n",
    "\n",
    "### Connectomes\n",
    "\n",
    "Let us now check the connectomes out to see for which subjects we have preprocessed functional connectivity data available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e404919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LH_VisCent_ExStr_2~LH_VisCent_ExStr_1</th>\n",
       "      <th>LH_VisCent_Striate_1~LH_VisCent_ExStr_1</th>\n",
       "      <th>LH_VisCent_Striate_1~LH_VisCent_ExStr_2</th>\n",
       "      <th>LH_VisCent_ExStr_3~LH_VisCent_ExStr_1</th>\n",
       "      <th>LH_VisCent_ExStr_3~LH_VisCent_ExStr_2</th>\n",
       "      <th>LH_VisCent_ExStr_3~LH_VisCent_Striate_1</th>\n",
       "      <th>LH_VisPeri_ExStrInf_1~LH_VisCent_ExStr_1</th>\n",
       "      <th>LH_VisPeri_ExStrInf_1~LH_VisCent_ExStr_2</th>\n",
       "      <th>LH_VisPeri_ExStrInf_1~LH_VisCent_Striate_1</th>\n",
       "      <th>LH_VisPeri_ExStrInf_1~LH_VisCent_ExStr_3</th>\n",
       "      <th>...</th>\n",
       "      <th>pCAU-lh~THA-VP-lh</th>\n",
       "      <th>pCAU-lh~THA-VA-lh</th>\n",
       "      <th>pCAU-lh~THA-DA-lh</th>\n",
       "      <th>pCAU-lh~NAc-shell-lh</th>\n",
       "      <th>pCAU-lh~NAc-core-lh</th>\n",
       "      <th>pCAU-lh~pGP-lh</th>\n",
       "      <th>pCAU-lh~aGP-lh</th>\n",
       "      <th>pCAU-lh~aPUT-lh</th>\n",
       "      <th>pCAU-lh~pPUT-lh</th>\n",
       "      <th>pCAU-lh~aCAU-lh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub-0001</th>\n",
       "      <td>0.533892</td>\n",
       "      <td>0.638701</td>\n",
       "      <td>0.560450</td>\n",
       "      <td>0.789158</td>\n",
       "      <td>0.466875</td>\n",
       "      <td>0.539399</td>\n",
       "      <td>0.677232</td>\n",
       "      <td>0.366597</td>\n",
       "      <td>0.361958</td>\n",
       "      <td>0.564919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072425</td>\n",
       "      <td>0.366347</td>\n",
       "      <td>0.327794</td>\n",
       "      <td>-0.069095</td>\n",
       "      <td>0.468919</td>\n",
       "      <td>-0.071477</td>\n",
       "      <td>0.040889</td>\n",
       "      <td>0.212324</td>\n",
       "      <td>0.173870</td>\n",
       "      <td>0.664122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0002</th>\n",
       "      <td>0.641335</td>\n",
       "      <td>0.663375</td>\n",
       "      <td>0.545326</td>\n",
       "      <td>0.629451</td>\n",
       "      <td>0.187963</td>\n",
       "      <td>0.390782</td>\n",
       "      <td>0.670098</td>\n",
       "      <td>0.116997</td>\n",
       "      <td>0.397939</td>\n",
       "      <td>0.742349</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048029</td>\n",
       "      <td>0.294397</td>\n",
       "      <td>0.247182</td>\n",
       "      <td>0.050190</td>\n",
       "      <td>0.069237</td>\n",
       "      <td>-0.133454</td>\n",
       "      <td>0.011535</td>\n",
       "      <td>0.265424</td>\n",
       "      <td>0.147957</td>\n",
       "      <td>0.587463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0003</th>\n",
       "      <td>0.657928</td>\n",
       "      <td>0.742613</td>\n",
       "      <td>0.453348</td>\n",
       "      <td>0.860049</td>\n",
       "      <td>0.523853</td>\n",
       "      <td>0.591320</td>\n",
       "      <td>0.770457</td>\n",
       "      <td>0.418997</td>\n",
       "      <td>0.645827</td>\n",
       "      <td>0.725303</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145307</td>\n",
       "      <td>0.240758</td>\n",
       "      <td>-0.014584</td>\n",
       "      <td>0.125811</td>\n",
       "      <td>0.397896</td>\n",
       "      <td>0.112837</td>\n",
       "      <td>0.292399</td>\n",
       "      <td>0.473047</td>\n",
       "      <td>0.224996</td>\n",
       "      <td>0.711400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0004</th>\n",
       "      <td>0.788957</td>\n",
       "      <td>0.694655</td>\n",
       "      <td>0.660015</td>\n",
       "      <td>0.732351</td>\n",
       "      <td>0.517771</td>\n",
       "      <td>0.387978</td>\n",
       "      <td>0.620954</td>\n",
       "      <td>0.283812</td>\n",
       "      <td>0.426040</td>\n",
       "      <td>0.622988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288743</td>\n",
       "      <td>0.276673</td>\n",
       "      <td>0.355181</td>\n",
       "      <td>0.250076</td>\n",
       "      <td>0.216825</td>\n",
       "      <td>-0.064241</td>\n",
       "      <td>0.045752</td>\n",
       "      <td>0.379170</td>\n",
       "      <td>0.226584</td>\n",
       "      <td>0.388584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0005</th>\n",
       "      <td>0.594372</td>\n",
       "      <td>0.761742</td>\n",
       "      <td>0.667648</td>\n",
       "      <td>0.791777</td>\n",
       "      <td>0.467393</td>\n",
       "      <td>0.515712</td>\n",
       "      <td>0.285025</td>\n",
       "      <td>-0.306764</td>\n",
       "      <td>0.179985</td>\n",
       "      <td>0.250133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009222</td>\n",
       "      <td>0.393067</td>\n",
       "      <td>0.032954</td>\n",
       "      <td>0.220143</td>\n",
       "      <td>0.289458</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>0.073975</td>\n",
       "      <td>0.515776</td>\n",
       "      <td>0.426828</td>\n",
       "      <td>0.701249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0923</th>\n",
       "      <td>0.580657</td>\n",
       "      <td>0.581537</td>\n",
       "      <td>0.456695</td>\n",
       "      <td>0.852308</td>\n",
       "      <td>0.345382</td>\n",
       "      <td>0.325712</td>\n",
       "      <td>0.656729</td>\n",
       "      <td>0.186045</td>\n",
       "      <td>0.466766</td>\n",
       "      <td>0.692227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356343</td>\n",
       "      <td>0.386007</td>\n",
       "      <td>0.461522</td>\n",
       "      <td>-0.158422</td>\n",
       "      <td>0.364220</td>\n",
       "      <td>-0.159627</td>\n",
       "      <td>-0.157892</td>\n",
       "      <td>0.505149</td>\n",
       "      <td>0.343721</td>\n",
       "      <td>0.622666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0924</th>\n",
       "      <td>0.772896</td>\n",
       "      <td>0.576773</td>\n",
       "      <td>0.382912</td>\n",
       "      <td>0.857393</td>\n",
       "      <td>0.595229</td>\n",
       "      <td>0.373345</td>\n",
       "      <td>0.384935</td>\n",
       "      <td>0.119016</td>\n",
       "      <td>0.407748</td>\n",
       "      <td>0.466081</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001937</td>\n",
       "      <td>0.384416</td>\n",
       "      <td>0.317110</td>\n",
       "      <td>-0.004191</td>\n",
       "      <td>0.178207</td>\n",
       "      <td>-0.105206</td>\n",
       "      <td>0.375226</td>\n",
       "      <td>0.427756</td>\n",
       "      <td>0.441114</td>\n",
       "      <td>0.711478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0925</th>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.674962</td>\n",
       "      <td>0.643015</td>\n",
       "      <td>0.708971</td>\n",
       "      <td>0.593741</td>\n",
       "      <td>0.415912</td>\n",
       "      <td>0.240876</td>\n",
       "      <td>0.030883</td>\n",
       "      <td>0.435190</td>\n",
       "      <td>0.354092</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123305</td>\n",
       "      <td>0.391051</td>\n",
       "      <td>0.101072</td>\n",
       "      <td>0.482087</td>\n",
       "      <td>0.363243</td>\n",
       "      <td>0.259769</td>\n",
       "      <td>0.127300</td>\n",
       "      <td>0.283468</td>\n",
       "      <td>0.446741</td>\n",
       "      <td>0.472104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0926</th>\n",
       "      <td>0.699854</td>\n",
       "      <td>0.751275</td>\n",
       "      <td>0.615963</td>\n",
       "      <td>0.834274</td>\n",
       "      <td>0.421496</td>\n",
       "      <td>0.565254</td>\n",
       "      <td>0.829891</td>\n",
       "      <td>0.371156</td>\n",
       "      <td>0.578320</td>\n",
       "      <td>0.874583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179298</td>\n",
       "      <td>0.550858</td>\n",
       "      <td>0.605740</td>\n",
       "      <td>0.030332</td>\n",
       "      <td>0.411371</td>\n",
       "      <td>0.123619</td>\n",
       "      <td>0.216562</td>\n",
       "      <td>0.465273</td>\n",
       "      <td>0.301320</td>\n",
       "      <td>0.666110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0927</th>\n",
       "      <td>0.704007</td>\n",
       "      <td>0.587890</td>\n",
       "      <td>0.530191</td>\n",
       "      <td>0.792209</td>\n",
       "      <td>0.678987</td>\n",
       "      <td>0.677505</td>\n",
       "      <td>0.632512</td>\n",
       "      <td>0.392710</td>\n",
       "      <td>0.567254</td>\n",
       "      <td>0.640225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079181</td>\n",
       "      <td>0.332753</td>\n",
       "      <td>0.391636</td>\n",
       "      <td>-0.162361</td>\n",
       "      <td>0.369515</td>\n",
       "      <td>-0.013173</td>\n",
       "      <td>0.136597</td>\n",
       "      <td>0.581985</td>\n",
       "      <td>0.545981</td>\n",
       "      <td>0.615678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>877 rows × 8646 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          LH_VisCent_ExStr_2~LH_VisCent_ExStr_1  \\\n",
       "sub-0001                               0.533892   \n",
       "sub-0002                               0.641335   \n",
       "sub-0003                               0.657928   \n",
       "sub-0004                               0.788957   \n",
       "sub-0005                               0.594372   \n",
       "...                                         ...   \n",
       "sub-0923                               0.580657   \n",
       "sub-0924                               0.772896   \n",
       "sub-0925                               0.836000   \n",
       "sub-0926                               0.699854   \n",
       "sub-0927                               0.704007   \n",
       "\n",
       "          LH_VisCent_Striate_1~LH_VisCent_ExStr_1  \\\n",
       "sub-0001                                 0.638701   \n",
       "sub-0002                                 0.663375   \n",
       "sub-0003                                 0.742613   \n",
       "sub-0004                                 0.694655   \n",
       "sub-0005                                 0.761742   \n",
       "...                                           ...   \n",
       "sub-0923                                 0.581537   \n",
       "sub-0924                                 0.576773   \n",
       "sub-0925                                 0.674962   \n",
       "sub-0926                                 0.751275   \n",
       "sub-0927                                 0.587890   \n",
       "\n",
       "          LH_VisCent_Striate_1~LH_VisCent_ExStr_2  \\\n",
       "sub-0001                                 0.560450   \n",
       "sub-0002                                 0.545326   \n",
       "sub-0003                                 0.453348   \n",
       "sub-0004                                 0.660015   \n",
       "sub-0005                                 0.667648   \n",
       "...                                           ...   \n",
       "sub-0923                                 0.456695   \n",
       "sub-0924                                 0.382912   \n",
       "sub-0925                                 0.643015   \n",
       "sub-0926                                 0.615963   \n",
       "sub-0927                                 0.530191   \n",
       "\n",
       "          LH_VisCent_ExStr_3~LH_VisCent_ExStr_1  \\\n",
       "sub-0001                               0.789158   \n",
       "sub-0002                               0.629451   \n",
       "sub-0003                               0.860049   \n",
       "sub-0004                               0.732351   \n",
       "sub-0005                               0.791777   \n",
       "...                                         ...   \n",
       "sub-0923                               0.852308   \n",
       "sub-0924                               0.857393   \n",
       "sub-0925                               0.708971   \n",
       "sub-0926                               0.834274   \n",
       "sub-0927                               0.792209   \n",
       "\n",
       "          LH_VisCent_ExStr_3~LH_VisCent_ExStr_2  \\\n",
       "sub-0001                               0.466875   \n",
       "sub-0002                               0.187963   \n",
       "sub-0003                               0.523853   \n",
       "sub-0004                               0.517771   \n",
       "sub-0005                               0.467393   \n",
       "...                                         ...   \n",
       "sub-0923                               0.345382   \n",
       "sub-0924                               0.595229   \n",
       "sub-0925                               0.593741   \n",
       "sub-0926                               0.421496   \n",
       "sub-0927                               0.678987   \n",
       "\n",
       "          LH_VisCent_ExStr_3~LH_VisCent_Striate_1  \\\n",
       "sub-0001                                 0.539399   \n",
       "sub-0002                                 0.390782   \n",
       "sub-0003                                 0.591320   \n",
       "sub-0004                                 0.387978   \n",
       "sub-0005                                 0.515712   \n",
       "...                                           ...   \n",
       "sub-0923                                 0.325712   \n",
       "sub-0924                                 0.373345   \n",
       "sub-0925                                 0.415912   \n",
       "sub-0926                                 0.565254   \n",
       "sub-0927                                 0.677505   \n",
       "\n",
       "          LH_VisPeri_ExStrInf_1~LH_VisCent_ExStr_1  \\\n",
       "sub-0001                                  0.677232   \n",
       "sub-0002                                  0.670098   \n",
       "sub-0003                                  0.770457   \n",
       "sub-0004                                  0.620954   \n",
       "sub-0005                                  0.285025   \n",
       "...                                            ...   \n",
       "sub-0923                                  0.656729   \n",
       "sub-0924                                  0.384935   \n",
       "sub-0925                                  0.240876   \n",
       "sub-0926                                  0.829891   \n",
       "sub-0927                                  0.632512   \n",
       "\n",
       "          LH_VisPeri_ExStrInf_1~LH_VisCent_ExStr_2  \\\n",
       "sub-0001                                  0.366597   \n",
       "sub-0002                                  0.116997   \n",
       "sub-0003                                  0.418997   \n",
       "sub-0004                                  0.283812   \n",
       "sub-0005                                 -0.306764   \n",
       "...                                            ...   \n",
       "sub-0923                                  0.186045   \n",
       "sub-0924                                  0.119016   \n",
       "sub-0925                                  0.030883   \n",
       "sub-0926                                  0.371156   \n",
       "sub-0927                                  0.392710   \n",
       "\n",
       "          LH_VisPeri_ExStrInf_1~LH_VisCent_Striate_1  \\\n",
       "sub-0001                                    0.361958   \n",
       "sub-0002                                    0.397939   \n",
       "sub-0003                                    0.645827   \n",
       "sub-0004                                    0.426040   \n",
       "sub-0005                                    0.179985   \n",
       "...                                              ...   \n",
       "sub-0923                                    0.466766   \n",
       "sub-0924                                    0.407748   \n",
       "sub-0925                                    0.435190   \n",
       "sub-0926                                    0.578320   \n",
       "sub-0927                                    0.567254   \n",
       "\n",
       "          LH_VisPeri_ExStrInf_1~LH_VisCent_ExStr_3  ...  pCAU-lh~THA-VP-lh  \\\n",
       "sub-0001                                  0.564919  ...           0.072425   \n",
       "sub-0002                                  0.742349  ...          -0.048029   \n",
       "sub-0003                                  0.725303  ...          -0.145307   \n",
       "sub-0004                                  0.622988  ...           0.288743   \n",
       "sub-0005                                  0.250133  ...          -0.009222   \n",
       "...                                            ...  ...                ...   \n",
       "sub-0923                                  0.692227  ...           0.356343   \n",
       "sub-0924                                  0.466081  ...          -0.001937   \n",
       "sub-0925                                  0.354092  ...          -0.123305   \n",
       "sub-0926                                  0.874583  ...           0.179298   \n",
       "sub-0927                                  0.640225  ...          -0.079181   \n",
       "\n",
       "          pCAU-lh~THA-VA-lh  pCAU-lh~THA-DA-lh  pCAU-lh~NAc-shell-lh  \\\n",
       "sub-0001           0.366347           0.327794             -0.069095   \n",
       "sub-0002           0.294397           0.247182              0.050190   \n",
       "sub-0003           0.240758          -0.014584              0.125811   \n",
       "sub-0004           0.276673           0.355181              0.250076   \n",
       "sub-0005           0.393067           0.032954              0.220143   \n",
       "...                     ...                ...                   ...   \n",
       "sub-0923           0.386007           0.461522             -0.158422   \n",
       "sub-0924           0.384416           0.317110             -0.004191   \n",
       "sub-0925           0.391051           0.101072              0.482087   \n",
       "sub-0926           0.550858           0.605740              0.030332   \n",
       "sub-0927           0.332753           0.391636             -0.162361   \n",
       "\n",
       "          pCAU-lh~NAc-core-lh  pCAU-lh~pGP-lh  pCAU-lh~aGP-lh  \\\n",
       "sub-0001             0.468919       -0.071477        0.040889   \n",
       "sub-0002             0.069237       -0.133454        0.011535   \n",
       "sub-0003             0.397896        0.112837        0.292399   \n",
       "sub-0004             0.216825       -0.064241        0.045752   \n",
       "sub-0005             0.289458        0.012017        0.073975   \n",
       "...                       ...             ...             ...   \n",
       "sub-0923             0.364220       -0.159627       -0.157892   \n",
       "sub-0924             0.178207       -0.105206        0.375226   \n",
       "sub-0925             0.363243        0.259769        0.127300   \n",
       "sub-0926             0.411371        0.123619        0.216562   \n",
       "sub-0927             0.369515       -0.013173        0.136597   \n",
       "\n",
       "          pCAU-lh~aPUT-lh  pCAU-lh~pPUT-lh  pCAU-lh~aCAU-lh  \n",
       "sub-0001         0.212324         0.173870         0.664122  \n",
       "sub-0002         0.265424         0.147957         0.587463  \n",
       "sub-0003         0.473047         0.224996         0.711400  \n",
       "sub-0004         0.379170         0.226584         0.388584  \n",
       "sub-0005         0.515776         0.426828         0.701249  \n",
       "...                   ...              ...              ...  \n",
       "sub-0923         0.505149         0.343721         0.622666  \n",
       "sub-0924         0.427756         0.441114         0.711478  \n",
       "sub-0925         0.283468         0.446741         0.472104  \n",
       "sub-0926         0.465273         0.301320         0.666110  \n",
       "sub-0927         0.581985         0.545981         0.615678  \n",
       "\n",
       "[877 rows x 8646 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connectomes = pd.read_csv(connectomes_path, sep=\"\\t\", index_col=0, compression=\"gzip\")\n",
    "connectomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0f5a83",
   "metadata": {},
   "source": [
    "In this dataframe again, **each row** corresponds to *one subject* from the study. **Each column** represents a *unique pairwise relationship* between two brain areas (also called an *edge* in graph theory terminology). That is, since a brain parcellation with **N** areas results in an **NxN** symmetric correlation matrix per subject, one half of a subjects matrix is discarded. Similarly, the diagonal of this correlation matrix is also typically discarded as the correlation of an area with itself is always 1. The remaining entries can be stacked and result in one row of this dataframe. Thus, each row contains **N x (N-1) / 2** entries. In our case, since the connectomes were processed with a combination of the Schaefer 100 cortical parcellation and the Tian 32 subcortical parcellation, this results in **100 x (100 - 1) / 2 = 8646** columns. This concept is illustrated by the graphic below:\n",
    "\n",
    "![title](images/connectomes.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb69a1e6",
   "metadata": {},
   "source": [
    "### Subsetting the data\n",
    "\n",
    "As you can see, the first dataframe on demographics contains 928 rows (i.e. subjects), whereas the second dataframe contains 877 rows. Let us for further analyses only select subjects for which we actually have connectomes. But first, let's also make sure, that we identify any 'NaN' values in the functional connectivity data and remove subjects with any 'NaN' entries.\n",
    "\n",
    "The pandas **isna()** method will check for each entry in the dataframe whether it is 'NaN' or not. That is, if an entry is 'NaN' it will return True and otherwise it will return False. We can use this to identify the indices (i.e. subjects) for which there are 'NaN' entries by combining it with the **any()** method provided by pandas.\n",
    "\n",
    "First see the output from **isna()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92e0553c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LH_VisCent_ExStr_2~LH_VisCent_ExStr_1</th>\n",
       "      <th>LH_VisCent_Striate_1~LH_VisCent_ExStr_1</th>\n",
       "      <th>LH_VisCent_Striate_1~LH_VisCent_ExStr_2</th>\n",
       "      <th>LH_VisCent_ExStr_3~LH_VisCent_ExStr_1</th>\n",
       "      <th>LH_VisCent_ExStr_3~LH_VisCent_ExStr_2</th>\n",
       "      <th>LH_VisCent_ExStr_3~LH_VisCent_Striate_1</th>\n",
       "      <th>LH_VisPeri_ExStrInf_1~LH_VisCent_ExStr_1</th>\n",
       "      <th>LH_VisPeri_ExStrInf_1~LH_VisCent_ExStr_2</th>\n",
       "      <th>LH_VisPeri_ExStrInf_1~LH_VisCent_Striate_1</th>\n",
       "      <th>LH_VisPeri_ExStrInf_1~LH_VisCent_ExStr_3</th>\n",
       "      <th>...</th>\n",
       "      <th>pCAU-lh~THA-VP-lh</th>\n",
       "      <th>pCAU-lh~THA-VA-lh</th>\n",
       "      <th>pCAU-lh~THA-DA-lh</th>\n",
       "      <th>pCAU-lh~NAc-shell-lh</th>\n",
       "      <th>pCAU-lh~NAc-core-lh</th>\n",
       "      <th>pCAU-lh~pGP-lh</th>\n",
       "      <th>pCAU-lh~aGP-lh</th>\n",
       "      <th>pCAU-lh~aPUT-lh</th>\n",
       "      <th>pCAU-lh~pPUT-lh</th>\n",
       "      <th>pCAU-lh~aCAU-lh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub-0001</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0002</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0003</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0004</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0005</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0923</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0924</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0925</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0926</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0927</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>877 rows × 8646 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          LH_VisCent_ExStr_2~LH_VisCent_ExStr_1  \\\n",
       "sub-0001                                  False   \n",
       "sub-0002                                  False   \n",
       "sub-0003                                  False   \n",
       "sub-0004                                  False   \n",
       "sub-0005                                  False   \n",
       "...                                         ...   \n",
       "sub-0923                                  False   \n",
       "sub-0924                                  False   \n",
       "sub-0925                                  False   \n",
       "sub-0926                                  False   \n",
       "sub-0927                                  False   \n",
       "\n",
       "          LH_VisCent_Striate_1~LH_VisCent_ExStr_1  \\\n",
       "sub-0001                                    False   \n",
       "sub-0002                                    False   \n",
       "sub-0003                                    False   \n",
       "sub-0004                                    False   \n",
       "sub-0005                                    False   \n",
       "...                                           ...   \n",
       "sub-0923                                    False   \n",
       "sub-0924                                    False   \n",
       "sub-0925                                    False   \n",
       "sub-0926                                    False   \n",
       "sub-0927                                    False   \n",
       "\n",
       "          LH_VisCent_Striate_1~LH_VisCent_ExStr_2  \\\n",
       "sub-0001                                    False   \n",
       "sub-0002                                    False   \n",
       "sub-0003                                    False   \n",
       "sub-0004                                    False   \n",
       "sub-0005                                    False   \n",
       "...                                           ...   \n",
       "sub-0923                                    False   \n",
       "sub-0924                                    False   \n",
       "sub-0925                                    False   \n",
       "sub-0926                                    False   \n",
       "sub-0927                                    False   \n",
       "\n",
       "          LH_VisCent_ExStr_3~LH_VisCent_ExStr_1  \\\n",
       "sub-0001                                  False   \n",
       "sub-0002                                  False   \n",
       "sub-0003                                  False   \n",
       "sub-0004                                  False   \n",
       "sub-0005                                  False   \n",
       "...                                         ...   \n",
       "sub-0923                                  False   \n",
       "sub-0924                                  False   \n",
       "sub-0925                                  False   \n",
       "sub-0926                                  False   \n",
       "sub-0927                                  False   \n",
       "\n",
       "          LH_VisCent_ExStr_3~LH_VisCent_ExStr_2  \\\n",
       "sub-0001                                  False   \n",
       "sub-0002                                  False   \n",
       "sub-0003                                  False   \n",
       "sub-0004                                  False   \n",
       "sub-0005                                  False   \n",
       "...                                         ...   \n",
       "sub-0923                                  False   \n",
       "sub-0924                                  False   \n",
       "sub-0925                                  False   \n",
       "sub-0926                                  False   \n",
       "sub-0927                                  False   \n",
       "\n",
       "          LH_VisCent_ExStr_3~LH_VisCent_Striate_1  \\\n",
       "sub-0001                                    False   \n",
       "sub-0002                                    False   \n",
       "sub-0003                                    False   \n",
       "sub-0004                                    False   \n",
       "sub-0005                                    False   \n",
       "...                                           ...   \n",
       "sub-0923                                    False   \n",
       "sub-0924                                    False   \n",
       "sub-0925                                    False   \n",
       "sub-0926                                    False   \n",
       "sub-0927                                    False   \n",
       "\n",
       "          LH_VisPeri_ExStrInf_1~LH_VisCent_ExStr_1  \\\n",
       "sub-0001                                     False   \n",
       "sub-0002                                     False   \n",
       "sub-0003                                     False   \n",
       "sub-0004                                     False   \n",
       "sub-0005                                     False   \n",
       "...                                            ...   \n",
       "sub-0923                                     False   \n",
       "sub-0924                                     False   \n",
       "sub-0925                                     False   \n",
       "sub-0926                                     False   \n",
       "sub-0927                                     False   \n",
       "\n",
       "          LH_VisPeri_ExStrInf_1~LH_VisCent_ExStr_2  \\\n",
       "sub-0001                                     False   \n",
       "sub-0002                                     False   \n",
       "sub-0003                                     False   \n",
       "sub-0004                                     False   \n",
       "sub-0005                                     False   \n",
       "...                                            ...   \n",
       "sub-0923                                     False   \n",
       "sub-0924                                     False   \n",
       "sub-0925                                     False   \n",
       "sub-0926                                     False   \n",
       "sub-0927                                     False   \n",
       "\n",
       "          LH_VisPeri_ExStrInf_1~LH_VisCent_Striate_1  \\\n",
       "sub-0001                                       False   \n",
       "sub-0002                                       False   \n",
       "sub-0003                                       False   \n",
       "sub-0004                                       False   \n",
       "sub-0005                                       False   \n",
       "...                                              ...   \n",
       "sub-0923                                       False   \n",
       "sub-0924                                       False   \n",
       "sub-0925                                       False   \n",
       "sub-0926                                       False   \n",
       "sub-0927                                       False   \n",
       "\n",
       "          LH_VisPeri_ExStrInf_1~LH_VisCent_ExStr_3  ...  pCAU-lh~THA-VP-lh  \\\n",
       "sub-0001                                     False  ...              False   \n",
       "sub-0002                                     False  ...              False   \n",
       "sub-0003                                     False  ...              False   \n",
       "sub-0004                                     False  ...              False   \n",
       "sub-0005                                     False  ...              False   \n",
       "...                                            ...  ...                ...   \n",
       "sub-0923                                     False  ...              False   \n",
       "sub-0924                                     False  ...              False   \n",
       "sub-0925                                     False  ...              False   \n",
       "sub-0926                                     False  ...              False   \n",
       "sub-0927                                     False  ...              False   \n",
       "\n",
       "          pCAU-lh~THA-VA-lh  pCAU-lh~THA-DA-lh  pCAU-lh~NAc-shell-lh  \\\n",
       "sub-0001              False              False                 False   \n",
       "sub-0002              False              False                 False   \n",
       "sub-0003              False              False                 False   \n",
       "sub-0004              False              False                 False   \n",
       "sub-0005              False              False                 False   \n",
       "...                     ...                ...                   ...   \n",
       "sub-0923              False              False                 False   \n",
       "sub-0924              False              False                 False   \n",
       "sub-0925              False              False                 False   \n",
       "sub-0926              False              False                 False   \n",
       "sub-0927              False              False                 False   \n",
       "\n",
       "          pCAU-lh~NAc-core-lh  pCAU-lh~pGP-lh  pCAU-lh~aGP-lh  \\\n",
       "sub-0001                False           False           False   \n",
       "sub-0002                False           False           False   \n",
       "sub-0003                False           False           False   \n",
       "sub-0004                False           False           False   \n",
       "sub-0005                False           False           False   \n",
       "...                       ...             ...             ...   \n",
       "sub-0923                False           False           False   \n",
       "sub-0924                False           False           False   \n",
       "sub-0925                False           False           False   \n",
       "sub-0926                False           False           False   \n",
       "sub-0927                False           False           False   \n",
       "\n",
       "          pCAU-lh~aPUT-lh  pCAU-lh~pPUT-lh  pCAU-lh~aCAU-lh  \n",
       "sub-0001            False            False            False  \n",
       "sub-0002            False            False            False  \n",
       "sub-0003            False            False            False  \n",
       "sub-0004            False            False            False  \n",
       "sub-0005            False            False            False  \n",
       "...                   ...              ...              ...  \n",
       "sub-0923            False            False            False  \n",
       "sub-0924            False            False            False  \n",
       "sub-0925            False            False            False  \n",
       "sub-0926            False            False            False  \n",
       "sub-0927            False            False            False  \n",
       "\n",
       "[877 rows x 8646 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isna = connectomes.isna()\n",
    "isna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e437ec81",
   "metadata": {},
   "source": [
    "The **any()** method will return whether any element along a given axis (i.e. along a row or a column) is True. The following output should be \"True\" therefore, if a subject has 'NaN' values and \"False\" otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9de12920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sub-0001    False\n",
       "sub-0002    False\n",
       "sub-0003    False\n",
       "sub-0004    False\n",
       "sub-0005    False\n",
       "            ...  \n",
       "sub-0923    False\n",
       "sub-0924    False\n",
       "sub-0925    False\n",
       "sub-0926    False\n",
       "sub-0927    False\n",
       "Length: 877, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isna_any = isna.any(axis=1)\n",
    "isna_any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d656b",
   "metadata": {},
   "source": [
    "We can do calculations on these boolean values as if they are 0's and 1's. That is, \"True\" will be counted as 1 and \"False\" will be counted as 0. We can therefore use the **.sum()** method to determine the number of 'NaN' values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec5686c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isna_any.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22fd78c",
   "metadata": {},
   "source": [
    "The output (\"0\") shows us that there aren't any 'NaN' values, so we can simply proceed with the data we have here. Let us therefore now subset the demographic data for which we have connectomes. That is, we will index the demographics dataset using the index from the connectomes dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8490e76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>handedness</th>\n",
       "      <th>BMI</th>\n",
       "      <th>education_level</th>\n",
       "      <th>background_SES</th>\n",
       "      <th>IST_fluid</th>\n",
       "      <th>IST_memory</th>\n",
       "      <th>IST_crystallised</th>\n",
       "      <th>IST_intelligence_total</th>\n",
       "      <th>...</th>\n",
       "      <th>sexual_attraction_M</th>\n",
       "      <th>sexual_attraction_F</th>\n",
       "      <th>gender_identity_M</th>\n",
       "      <th>gender_identity_F</th>\n",
       "      <th>religious_upbringing</th>\n",
       "      <th>religious_now</th>\n",
       "      <th>religious_importance</th>\n",
       "      <th>DWI_TR_run1</th>\n",
       "      <th>DWI_TR_run2</th>\n",
       "      <th>DWI_TR_run3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub-0001</th>\n",
       "      <td>22.00</td>\n",
       "      <td>female</td>\n",
       "      <td>right</td>\n",
       "      <td>23</td>\n",
       "      <td>medium</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.312</td>\n",
       "      <td>6.312</td>\n",
       "      <td>6.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0002</th>\n",
       "      <td>21.75</td>\n",
       "      <td>female</td>\n",
       "      <td>right</td>\n",
       "      <td>20</td>\n",
       "      <td>medium</td>\n",
       "      <td>5.5</td>\n",
       "      <td>97.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0003</th>\n",
       "      <td>25.25</td>\n",
       "      <td>female</td>\n",
       "      <td>right</td>\n",
       "      <td>31</td>\n",
       "      <td>high</td>\n",
       "      <td>3.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.312</td>\n",
       "      <td>6.312</td>\n",
       "      <td>6.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0004</th>\n",
       "      <td>22.50</td>\n",
       "      <td>female</td>\n",
       "      <td>right</td>\n",
       "      <td>20</td>\n",
       "      <td>high</td>\n",
       "      <td>5.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0005</th>\n",
       "      <td>22.25</td>\n",
       "      <td>male</td>\n",
       "      <td>right</td>\n",
       "      <td>23</td>\n",
       "      <td>high</td>\n",
       "      <td>4.5</td>\n",
       "      <td>112.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0923</th>\n",
       "      <td>21.75</td>\n",
       "      <td>male</td>\n",
       "      <td>right</td>\n",
       "      <td>19</td>\n",
       "      <td>medium</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.733</td>\n",
       "      <td>6.733</td>\n",
       "      <td>6.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0924</th>\n",
       "      <td>22.25</td>\n",
       "      <td>male</td>\n",
       "      <td>right</td>\n",
       "      <td>21</td>\n",
       "      <td>medium</td>\n",
       "      <td>3.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.374</td>\n",
       "      <td>6.374</td>\n",
       "      <td>6.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0925</th>\n",
       "      <td>25.25</td>\n",
       "      <td>male</td>\n",
       "      <td>right</td>\n",
       "      <td>30</td>\n",
       "      <td>medium</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0926</th>\n",
       "      <td>20.75</td>\n",
       "      <td>male</td>\n",
       "      <td>right</td>\n",
       "      <td>22</td>\n",
       "      <td>high</td>\n",
       "      <td>2.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.312</td>\n",
       "      <td>6.312</td>\n",
       "      <td>6.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0927</th>\n",
       "      <td>24.25</td>\n",
       "      <td>female</td>\n",
       "      <td>right</td>\n",
       "      <td>35</td>\n",
       "      <td>medium</td>\n",
       "      <td>2.5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "      <td>6.311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>877 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age     sex handedness  BMI education_level  background_SES  \\\n",
       "sub-0001  22.00  female      right   23          medium             2.0   \n",
       "sub-0002  21.75  female      right   20          medium             5.5   \n",
       "sub-0003  25.25  female      right   31            high             3.0   \n",
       "sub-0004  22.50  female      right   20            high             5.0   \n",
       "sub-0005  22.25    male      right   23            high             4.5   \n",
       "...         ...     ...        ...  ...             ...             ...   \n",
       "sub-0923  21.75    male      right   19          medium             3.0   \n",
       "sub-0924  22.25    male      right   21          medium             3.0   \n",
       "sub-0925  25.25    male      right   30          medium             4.0   \n",
       "sub-0926  20.75    male      right   22            high             2.0   \n",
       "sub-0927  24.25  female      right   35          medium             2.5   \n",
       "\n",
       "          IST_fluid  IST_memory  IST_crystallised  IST_intelligence_total  \\\n",
       "sub-0001       77.0        49.0              33.0                   159.0   \n",
       "sub-0002       97.0        63.0              39.0                   199.0   \n",
       "sub-0003      122.0        67.0              38.0                   227.0   \n",
       "sub-0004      149.0        69.0              52.0                   270.0   \n",
       "sub-0005      112.0        57.0              43.0                   212.0   \n",
       "...             ...         ...               ...                     ...   \n",
       "sub-0923       70.0        49.0              34.0                   153.0   \n",
       "sub-0924      136.0        56.0              54.0                   246.0   \n",
       "sub-0925       64.0        37.0              49.0                   150.0   \n",
       "sub-0926       84.0        44.0              33.0                   161.0   \n",
       "sub-0927       98.0        57.0              35.0                   190.0   \n",
       "\n",
       "          ...  sexual_attraction_M  sexual_attraction_F  gender_identity_M  \\\n",
       "sub-0001  ...                  7.0                  1.0                1.0   \n",
       "sub-0002  ...                  7.0                  1.0                2.0   \n",
       "sub-0003  ...                  6.0                  3.0                1.0   \n",
       "sub-0004  ...                  6.0                  2.0                1.0   \n",
       "sub-0005  ...                  1.0                  7.0                6.0   \n",
       "...       ...                  ...                  ...                ...   \n",
       "sub-0923  ...                  1.0                  7.0                7.0   \n",
       "sub-0924  ...                  2.0                  6.0                4.0   \n",
       "sub-0925  ...                  1.0                  7.0                7.0   \n",
       "sub-0926  ...                  NaN                  NaN                NaN   \n",
       "sub-0927  ...                  7.0                  2.0                1.0   \n",
       "\n",
       "          gender_identity_F  religious_upbringing  religious_now  \\\n",
       "sub-0001                7.0                    no            yes   \n",
       "sub-0002                7.0                    no             no   \n",
       "sub-0003                6.0                    no             no   \n",
       "sub-0004                7.0                   yes             no   \n",
       "sub-0005                1.0                    no             no   \n",
       "...                     ...                   ...            ...   \n",
       "sub-0923                1.0                    no             no   \n",
       "sub-0924                4.0                    no             no   \n",
       "sub-0925                1.0                    no             no   \n",
       "sub-0926                NaN                   yes            yes   \n",
       "sub-0927                7.0                    no             no   \n",
       "\n",
       "          religious_importance  DWI_TR_run1  DWI_TR_run2  DWI_TR_run3  \n",
       "sub-0001                   2.0        6.312        6.312        6.312  \n",
       "sub-0002                   NaN          NaN        6.311        6.311  \n",
       "sub-0003                   NaN        6.312        6.312        6.312  \n",
       "sub-0004                   NaN        6.311        6.311        6.311  \n",
       "sub-0005                   NaN        6.311        6.311        6.311  \n",
       "...                        ...          ...          ...          ...  \n",
       "sub-0923                   NaN        6.733        6.733        6.733  \n",
       "sub-0924                   NaN        6.374        6.374        6.374  \n",
       "sub-0925                   NaN        6.311        6.311        6.311  \n",
       "sub-0926                   5.0        6.312        6.312        6.312  \n",
       "sub-0927                   NaN        6.311        6.311        6.311  \n",
       "\n",
       "[877 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsampled_demographics = demographics.loc[connectomes.index]\n",
    "subsampled_demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980d92e5",
   "metadata": {},
   "source": [
    "The indexing using the **.loc()** method importantly also ensures that the rows in both dataframes are in the same order which will be important later when we convert them to numpy arrays, a data structure that scikit-learn understands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfed3214",
   "metadata": {},
   "source": [
    "### Exploring our sample:\n",
    "\n",
    "Now that the samples in the connectome data and the demographics data are matched, let's take a quick look at sex and age to get an overview of our sample.\n",
    "\n",
    "The **value_counts()** method takes a pandas series (i.e. a column from the dataframe) and counts the amount of times each possible value is contained in the column. This is a good way of discovering what values are possible for a specific variable, and how many instances there are for each value. This is useful for example when looking at the sex information of a sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee755abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female    454\n",
       "male      423\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsampled_demographics[\"sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413de870",
   "metadata": {},
   "source": [
    "The **plot.hist()** pandas method provides a quick way of making a histogram that we can also group by \"sex\" to look at each distribution seperately: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e340d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot: title={'center': 'female'}, ylabel='Frequency'>,\n",
       "       <AxesSubplot: title={'center': 'male'}, ylabel='Frequency'>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "subsampled_demographics.plot.hist(column=[\"age\"], by=\"sex\", figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fa930a",
   "metadata": {},
   "source": [
    "As you can see, the age range is quite narrow, and limited to young people. This is a common problem in neuroimaging or psychology studies, which often sample students from their universities for convenience. It is always good to be aware of these limitations before starting any complicated machine learning pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce09c14",
   "metadata": {},
   "source": [
    "## Doing some ML\n",
    "\n",
    "Now, lets try to build a classifier that can distinguish between males and females given a functional connectome. That is, the connectomes will be the features ('X') and the sex will be the target ('y'). Since \"sex\" in our data is encoded as \"male\" and \"female\" and scikit-learn only understands numeric data, we have to convert \"sex\" to a numeric, categorial variable. Since it's a binary target, this is relatively straightforward. We can do this simply by adding another column to our demographics data as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b86ccfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled_demographics[\"sex_numeric\"] = subsampled_demographics[\"sex\"].map(lambda x: 1 if x == \"female\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dff35c",
   "metadata": {},
   "source": [
    "We can inspect the output as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "458a222c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>sex_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sub-0001</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0002</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0003</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0004</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0005</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0923</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0924</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0925</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0926</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-0927</th>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>877 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sex  sex_numeric\n",
       "sub-0001  female            1\n",
       "sub-0002  female            1\n",
       "sub-0003  female            1\n",
       "sub-0004  female            1\n",
       "sub-0005    male            0\n",
       "...          ...          ...\n",
       "sub-0923    male            0\n",
       "sub-0924    male            0\n",
       "sub-0925    male            0\n",
       "sub-0926    male            0\n",
       "sub-0927  female            1\n",
       "\n",
       "[877 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_info = subsampled_demographics[[\"sex\", \"sex_numeric\"]]\n",
    "sex_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4cd7d8",
   "metadata": {},
   "source": [
    "As you can see, there is a 1 where sex is given as \"female\" and a 0 where sex is given as male. Let's finalise the target as a numpy array which is a data structure scikit-learn understands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37c50c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = np.array(sex_info[\"sex_numeric\"])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7913d282",
   "metadata": {},
   "source": [
    "### Train-test split\n",
    "\n",
    "Let us first split the data so we have one hold-out validation set that will be left untouched for now. Let us also finalise our features as a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6a127d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(connectomes)\n",
    "\n",
    "X_model_selection, X_holdout, y_model_selection, y_holdout = train_test_split(X, y, random_state=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea919d4b",
   "metadata": {},
   "source": [
    "We will then do another train-test split on the model selection data, so that we can train models on the inner training set, compare their performance on the inner test set, and then evaluate our final model on the hold-out validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e505a997",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_inner_train, X_inner_test, y_inner_train, y_inner_test = \\\n",
    "    train_test_split(X_model_selection, y_model_selection, random_state=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b3ef4",
   "metadata": {},
   "source": [
    "### Fitting a bunch of models\n",
    "\n",
    "Every problem, every classification or regression task is different, and therefore requires a different model. That is, which model works best depends on the underlying processes that generate the distribution of our X and on the \"true\" function that maps X to y. In other words, we cannot really know which model will work best before we try it out. Let us test out a few popular options therefore starting with **Logistic Regression**. Now, although it is called **Logistic Regression** this is actually a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efbb4eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd61e3f",
   "metadata": {},
   "source": [
    "We can initialise the LogisticRegression object, and then fit it on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e2388fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed43a8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.fit(X_inner_train, y_inner_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8bb990",
   "metadata": {},
   "source": [
    "We can now test the accuracy of this classifier by making predictions on our test set that was so far unseen. The predictions can then be compared to the true values of y in this test set using some metric (for example \"accuracy\" in our case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b07c873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_log_reg = logistic_regression.predict(X_inner_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccbd8131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7ae474b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_inner_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2df5b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75f593a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.806060606060606"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_inner_test, predictions_log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba5cd92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
